{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmzYqXRvNkkV",
        "outputId": "92500206-2409-4063-a264-2f3cd62d02db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "file_path = '/content/drive/MyDrive/GYAFC_Corpus/Entertainment_Music/train/informal'   # Replace 'your_text_file.txt' with the path to your text file\n",
        "with open(file_path, 'r') as file:\n",
        "    X = file.readlines()\n",
        "\n",
        "for i  in range(len(X)):\n",
        "  X[i] = X[i].split(\"\\n\")[0]\n",
        "  X[i] = X[i].lower()"
      ],
      "metadata": {
        "id": "5FURCUDhN_nZ"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzJVXj72OfUl",
        "outputId": "d3145725-c444-4fd6-da7c-dc902b367cbd"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[40000:46000]"
      ],
      "metadata": {
        "id": "pTxAvnQNOpb4"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding token 0 to informal sentences\n",
        "y  = []\n",
        "for i in range(len(X)):\n",
        "    y.append(0)"
      ],
      "metadata": {
        "id": "d_g2YPUROwVH"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/GYAFC_Corpus/Entertainment_Music/train/formal'   # Replace 'your_text_file.txt' with the path to your text file\n",
        "with open(file_path, 'r') as file:\n",
        "    X_formal = file.readlines()\n",
        "\n",
        "for i  in range(len(X_formal)):\n",
        "  X_formal[i] = X_formal[i].split(\"\\n\")[0]\n",
        "  X_formal[i] = X_formal[i].lower()"
      ],
      "metadata": {
        "id": "rI5Um8jtPXYi"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_formal = X_formal[40000:46000]"
      ],
      "metadata": {
        "id": "i-duf8LmPq6a"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding token 1 to formal sentences\n",
        "y_formal = []\n",
        "for i in range(len(X_formal)):\n",
        "  y_formal.append(1)"
      ],
      "metadata": {
        "id": "0AiuWgLhPyvm"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_formal = {\"X\" : X_formal,\n",
        "               \"y\": y_formal}\n",
        "dict_informal = {\"X\": X,\n",
        "                 \"y\": y}\n",
        "import pandas as pd\n",
        "df_formal = pd.DataFrame(dict_formal)\n",
        "df_informal = pd.DataFrame(dict_informal)\n",
        "df = pd.concat([df_formal,df_informal],axis = 0)"
      ],
      "metadata": {
        "id": "D1jF0-OXQD6f"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['X'].tolist(), df['y'].tolist(), test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "IGqr6JTNRO__"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 2: Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['X'].tolist(), df['y'].tolist(), test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenized_inputs_train = tokenizer(X_train, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "tokenized_inputs_test = tokenizer(X_test, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Step 4: Create PyTorch Dataset\n",
        "class FormalityDataset(Dataset):\n",
        "    def __init__(self, tokenized_inputs, labels):\n",
        "        self.tokenized_inputs = tokenized_inputs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.tokenized_inputs[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.tokenized_inputs[\"attention_mask\"][idx],\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "train_dataset = FormalityDataset(tokenized_inputs_train, y_train)\n",
        "test_dataset = FormalityDataset(tokenized_inputs_test, y_test)\n",
        "\n",
        "# Step 5: Fine-Tune the Model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Move the model to the appropriate device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Move input tensors to the same device as the model\n",
        "inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "# Fine-tuning loop\n",
        "model.train()\n",
        "for epoch in range(3):  # Adjust number of epochs as needed\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = {key: value.to(device) for key, value in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Step 6: Save Model and Tokenizer Configurations\n",
        "model.save_pretrained(\"model_configs_fscore\")\n",
        "tokenizer.save_pretrained(\"tokenizer_configs_fscore\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI3rnFFRRP_7",
        "outputId": "8b2406b9-edef-497b-e7bc-f61740313be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer_configs_fscore/tokenizer_config.json',\n",
              " 'tokenizer_configs_fscore/special_tokens_map.json',\n",
              " 'tokenizer_configs_fscore/vocab.txt',\n",
              " 'tokenizer_configs_fscore/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Step 1: Load the Model and Tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/model_configs_fscore\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/tokenizer_configs_fscore\")\n",
        "\n",
        "# Step 2: Tokenization\n",
        "text = input()\n",
        "inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# Step 3: Prepare Input Tensors\n",
        "input_ids = inputs[\"input_ids\"]\n",
        "attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "# Move tensors to the appropriate device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_ids = input_ids.to(device)\n",
        "attention_mask = attention_mask.to(device)\n",
        "model.to(device)\n",
        "\n",
        "# Step 4: Forward Pass\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# Apply softmax to obtain probabilities\n",
        "probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "# Extract formality scores\n",
        "formality_score = probabilities[0][1].item()  # Probability of class 1 (informal)\n",
        "\n",
        "\n",
        "print(\"Formality Score:\", formality_score)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BHvieW0yTMsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f2e2ef-35d1-42cd-f9cf-9ae84b0212aa"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how are you doing?\n",
            "Formality Score: 0.8359653353691101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-AG8cDaDfW3",
        "outputId": "d24f0fd6-238f-4a6b-eeec-8099ca68c530"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2400"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Step 4: Create PyTorch Dataset\n",
        "class FormalityDataset(Dataset):\n",
        "    def __init__(self, tokenized_inputs, labels):\n",
        "        self.tokenized_inputs = tokenized_inputs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": self.tokenized_inputs[\"input_ids\"][idx],\n",
        "            \"attention_mask\": self.tokenized_inputs[\"attention_mask\"][idx],\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenized_inputs_test = tokenizer(X_test, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "test_dataset = FormalityDataset(tokenized_inputs_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "\n",
        "# List to store true labels and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=1).tolist()\n",
        "\n",
        "        # Store true and predicted labels\n",
        "        true_labels.extend(labels.tolist())\n",
        "        predicted_labels.extend(predictions)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgRKQGcNWdlS",
        "outputId": "c54b6a00-f26a-4a4b-ede9-d47b11c0616e"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 928  236]\n",
            " [ 170 1066]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score , recall_score\n",
        "print(\"Recall_score:\",recall_score(true_labels, predicted_labels))\n",
        "print(\"Precision_score:\", precision_score(true_labels,predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ze1XXg8cEQX",
        "outputId": "f58e8fc6-643b-4810-e6f3-964e15e0d432"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall_score: 0.8624595469255664\n",
            "Precision_score: 0.8187403993855606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iz1GLMtFc10b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}